{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Item XIX\n",
    "\n",
    "Implement the Conjugate Gradient Method with symmetric preconditioner. Select a convenient problem of your choice, but not a trivial one and test it. Please describe the problem and implementation completely.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a regular version of the Conjugate Gradient, but generalized\n",
    "# so the preconditioner can be added as a function that multiplies a vector\n",
    "# (by default this function keeps it as it is)\n",
    "def conjugate_gradient(A,b,pinv=lambda x:x,x0=None,threshold=1e-12):\n",
    "    n = A.shape[0]\n",
    "    if x0 is None: x0 = np.zeros(n)\n",
    "    #\n",
    "    r0 = b - np.dot(A,x0) # Initial residual.\n",
    "    z0 = pinv(r0) # Initial residual after using the preconditioner.\n",
    "    p0 = z0 # First conjugate vector (P^-1 A) (basis)\n",
    "    #\n",
    "    xk = x0\n",
    "    rk = r0\n",
    "    pk = p0\n",
    "    zk = z0\n",
    "    #\n",
    "    for k in range(n):\n",
    "        ak = np.dot(rk,zk)/np.dot(pk,np.dot(A,pk))\n",
    "        # ^ coefficient for pk on x that minimizes next residual\n",
    "        xk1 = xk + ak*pk\n",
    "        # ^ Update x, add the projection on the direction of the new conjugate vector\n",
    "        rk1 = rk - ak*np.dot(A,pk)\n",
    "        # ^ Update residual\n",
    "        zk1 = pinv(rk1)\n",
    "        # ^ Residual after using preconditioner\n",
    "        divi = np.dot(zk,rk)\n",
    "        if np.abs(divi)<threshold: break # Terminate if residual is too small\n",
    "        bk = np.dot(zk1,rk1)/divi\n",
    "        pk1 = zk1 + bk*pk\n",
    "        # ^ Next conjugate vector\n",
    "        #\n",
    "        # Move forward\n",
    "        xk = xk1\n",
    "        rk = rk1\n",
    "        pk = pk1\n",
    "        zk = zk1\n",
    "    return xk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.71413712 0.9620883  0.44807942 0.93563933 0.42363722]\n",
      " [0.9620883  3.78608239 0.45631339 0.95419135 0.43249863]\n",
      " [0.44807942 0.45631339 1.76162215 0.44376439 0.20093234]\n",
      " [0.93563933 0.95419135 0.44376439 3.68251236 0.42075958]\n",
      " [0.42363722 0.43249863 0.20093234 0.42075958 1.66880361]]\n",
      "[0.62500652 0.06863122 0.42105896 0.62394209 0.93272038]\n",
      "[ 0.09380268 -0.10832627  0.15998423  0.09497974  0.51996736]\n",
      "[ 0.09380268 -0.10832627  0.15998423  0.09497974  0.51996736]\n"
     ]
    }
   ],
   "source": [
    "def random_positive_definite_diag_dominant_matrix(n):\n",
    "    # We create a simetric matrix multiplying a matrix by itself\n",
    "    # the values decrease fast while descending with the diagonal\n",
    "    # (the idea is to make it ill-conditioned)\n",
    "    a = np.random.random((n,n)) * (np.arange(1.0,n+1)**-4)\n",
    "    A = np.dot(a,a.T)\n",
    "    # We change the diagonal to make it diagonal dominant\n",
    "    sumr = np.sum(A,axis=0)\n",
    "    np.fill_diagonal(A,sumr)\n",
    "    return A\n",
    "# Just test code.\n",
    "N = 5\n",
    "A = random_positive_definite_diag_dominant_matrix(N)\n",
    "b = np.random.random(N)\n",
    "print(A)\n",
    "print(b)\n",
    "x1 = np.linalg.solve(A,b)\n",
    "x2 = conjugate_gradient(A,b)\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the Jacobi preconditioner (the preconditioner is the diagonal of the matrix, so the inverse is simple), that is good for diagonal dominant matrices and also is simmetrical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_preconditioner_inv(A):\n",
    "    P = np.diag(A)**-1\n",
    "    return lambda x: P*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n=10:\n",
      "\tregular error: 1.1537243382875318e-12\n",
      "\tprecond error: 7.099800403143064e-09\n",
      "For n=100:\n",
      "\tregular error: 1.6401885656949777e-08\n",
      "\tprecond error: 5.764102297550755e-10\n",
      "For n=1000:\n",
      "\tregular error: 1.4263998411277735e-08\n",
      "\tprecond error: 4.822434864631964e-13\n",
      "For n=2000:\n",
      "\tregular error: 1.4045056901688947e-08\n",
      "\tprecond error: 6.827028872780083e-14\n"
     ]
    }
   ],
   "source": [
    "NS = (10,100,1000,2000)\n",
    "\n",
    "for nn in NS:\n",
    "    AA = random_positive_definite_diag_dominant_matrix(nn)\n",
    "    bb = np.random.random(nn)\n",
    "    xx = conjugate_gradient(AA,bb)\n",
    "    xx2 = conjugate_gradient(AA,bb,pinv=jacobi_preconditioner_inv(AA))\n",
    "    # Check error:\n",
    "    print(\"For n=%d:\"%nn)\n",
    "    err = np.mean(np.abs(np.dot(AA,xx)-bb))\n",
    "    print(\"\\tregular error: \"+str(err))\n",
    "    err2 = np.mean(np.abs(np.dot(AA,xx2)-bb))\n",
    "    print(\"\\tprecond error: \"+str(err2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it allows us to decrease the error when $n$ gets larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
