{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item I\n",
    "\n",
    "What is a..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Singular matrix\n",
    "\n",
    "A square matrix ($n\\times n$) $A$ is singular if there doesn't exist a square matrix ($n \\times n$) $B$ such that:\n",
    "$$\n",
    "BA = I_n \\, \\wedge \\, AB = I_n\n",
    "$$\n",
    "where $I_n$ is the $n \\times n$ identity matrix. $B$ is denoted as $A^{-1}$.\n",
    "\n",
    "The following conditions for $A$ are equivalent:\n",
    "* $A$ is singular.\n",
    "* Its determinant is 0.\n",
    "* At least one of its eigenvalues is 0.\n",
    "* $\\text{rank}(A) < n $.\n",
    "* The equation $A\\vec{x} = \\vec{0}$ has infinite solutions.\n",
    "\n",
    "Properties:\n",
    "* The equation $A\\vec{x} = \\vec{b}$, with $\\vec{b}\\neq \\vec{0}$, can have zero or infinite solutions.\n",
    "* $(A^{-1})^{-1} = A$.\n",
    "* $(kA)^{-1} = k^{-1} A^{-1}$, if $k \\neq 0$.\n",
    "* $(A^T)^{-1} = (A^{-1})^T$\n",
    "* $\\text{det}(A^{-1}) = \\text{det}(A)^{-1}$\n",
    "* $A^{-1} = Q \\Lambda^{-1} Q^{-1}$, where $Q$ and $\\Lambda$ are matrices obtained from the [eigendecomposition](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix) of the matrix: $A = Q \\Lambda Q^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Vandermonde matrix\n",
    "\n",
    "Is a $m \\times n$ matrix with the following structure:\n",
    "$$\n",
    "V = \\begin{bmatrix}1&\\alpha _{1}&\\alpha _{1}^{2}&\\dots &\\alpha _{1}^{n-1}\\\\1&\\alpha _{2}&\\alpha _{2}^{2}&\\dots &\\alpha _{2}^{n-1}\\\\1&\\alpha _{3}&\\alpha _{3}^{2}&\\dots &\\alpha _{3}^{n-1}\\\\\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\1&\\alpha _{m}&\\alpha _{m}^{2}&\\dots &\\alpha _{m}^{n-1}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* It evaluates a polynomial at a set of points. It maps the coefficients of a polynomial to the value it acquires at the $\\alpha_i$'s.\n",
    "* $\\det(V) = \\prod_{1\\leq i < j \\leq n} (\\alpha_j-\\alpha_i)$.\n",
    "* A $m \\times n$ rectangular Vandermonde matrix such that $m \\leq n$ has maximum rank $m$ iff all $x_i$ are distinct.\n",
    "* A $m \\times n$ rectangular Vandermonde matrix such that $n \\leq m$ has maximum rank $n$ iff there are $n$ of the $\\alpha_i$ that are distinct.\n",
    "* A $n \\times n$ Vandermonde matrix is invertible iff the $\\alpha_i$ are distinct. [A direct formula to compute it is known](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19660023042.pdf).\n",
    "* The discrete Fourier transform is defined by the [DFT matrix](https://en.wikipedia.org/wiki/DFT_matrix), which is a specific Vandermonde matrix where the numbers $\\alpha_i$ are chosen to be roots of unity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Symmetric matrix\n",
    "\n",
    "A square matrix $A$ so that $A = A^T$.\n",
    "\n",
    "* Every square diagonal matrix is symmetric.\n",
    "* With $A,B$ symmetric, $A+B$ is symmetric.\n",
    "* With $A,B$ symmetric, iff $AB=BA$, then $AB$ is symmetric.\n",
    "* Given $n$ integer, $A^n$ is symmetric.\n",
    "* If $A^{-1}$ exists, it is symmetric.\n",
    "* If $A \\in \\mathbb{R}^{n\\times n}$, then $\\langle A\\vec{x}, \\vec{y} \\rangle = \\langle \\vec{x}, A\\vec{y} \\rangle \\quad \\forall \\vec{x},\\vec{y}, \\in \\mathbb{R}^n$\n",
    "* If $A$ is congruent with $R$, i.e. there exists an invertible matrix $P$ so that $P^T AP = B$, then $B$ is also symmetric.\n",
    "* Every squared real matrix can be docmposed into two real symmetric matrices.\n",
    "* If $A \\in \\mathbb{R}$, it is also hermitian (and has their properties!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Hermitian matrix\n",
    "\n",
    "A square matrix $A$ so that $A = A^*$, where $A^* = \\overline{A^T}$.\n",
    "* $a_{ij} = \\overline{a_{ji}}$\n",
    "* All the eigenvalues $A$ are real.\n",
    "* $A$ is normal, i.e. $A^*A = AA^*$.\n",
    "* $\\langle \\vec{v}, A\\vec{v} \\rangle \\in \\mathbb{R}$\n",
    "* If $A$ is also positive-definite (i.e. $\\vec{z}^* A \\vec{z} > 0, \\forall z \\neq \\vec{0}$), then $A=LL^*$ where $L$ is a lower-triangular matrix.\n",
    "    * This is the [Cholesky decomposition](https://en.wikipedia.org/wiki/Cholesky_decomposition), more efficient than $LU$ decomposition for solving systems of linear equations.\n",
    "* $\\langle \\vec{v}, A \\vec{w} \\rangle = \\langle A\\vec{v}, \\vec{w} \\rangle$\n",
    "* With $A,B$ hermitian, $A+B$ is hermitian.\n",
    "* With $A,B$ hermitian, if $AB=BA$, then $AB$ is hermitian.\n",
    "* Given $n$ integer, $A^n$ is hermitian.\n",
    "* $A$ can be diagonalized: $A= Q\\Lambda Q^T$, where $Q$ is a unitary matrix.\n",
    "    * $Q$ is composed of orthonormal eigenvectors of $A$ and $\\Lambda$ is diagonal, having the eigenvalues of $A$.\n",
    "    * It holds that $$\n",
    "    A = \\sum_j \\lambda_j u_j u_j^* \\,,\n",
    "    $$ where the $u_j$'s are the orthonormal eigenvectors and the $\\lambda_j$'s are the eigenvalues.\n",
    "    * This is the [eigendecomposition](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix) of $A$.\n",
    "* $B + B^*$ is Hermitian, for a square matrix $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Skew-hermitian matrix\n",
    "\n",
    "A square matrix $A$ so that $A^* = -A$, where $A^* = \\overline{A^T}$.\n",
    "\n",
    "The following conditions are equivalent:\n",
    "* The real part $\\mathfrak{R}(A)$ is skew-symmetric and the imaginary part $\\mathfrak{I}(A)$ is symmetric.\n",
    "* $iA$ is Hermitian.\n",
    "* $-iA$ is Hermitian.\n",
    "* $x^*Ay=-y^*Ax$ for all vectors $x,y$.\n",
    "\n",
    "Properties:\n",
    "* $a_{ij} = -\\overline{a_{ji}}$\n",
    "* All the eigenvalues of a $A$ are purely imaginary (possibly zero).\n",
    "* It is normal (i.e. $A^*A = AA^*$).\n",
    "  * $\\Rightarrow$ it is diagonalizable ($A = VDV^*$ with $V$ unitary and $D$ diagonal).\n",
    "  * Its eigenvectors for distinct eigenvalues are orthogonal.\n",
    "* All $a_{ii}$ (values in the diagonal) have to be purely imaginary (possibly zero).\n",
    "* With $A,B$ skew-Hermitian, $A+B$ is skew-hermitian.\n",
    "* $A^k$ is Hermitian if $k$ is even and skew-Hermitian if $k$ is odd.\n",
    "* $B - B^*$ is skew-Hermitian, for a square matrix $B$.\n",
    "* An arbitrary square matrix $X$ can be writeen as the sum of a Hermitian matrix $H$ and a skew-Hermitian matrix $S$:\n",
    "$$\n",
    "X = H + S \\quad \\text{with} \\quad H = \\tfrac{1}{2}(X+X^*) \\quad \\text{and} \\quad S = \\tfrac{1}{2}(X-X^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Unitary matrix\n",
    "\n",
    "A square matrix $U$ is unitary if $U^*$ is also its inverse $U^{-1}$:\n",
    "$$\n",
    "U^* U = U U^* = I\n",
    "$$\n",
    "\n",
    "The following conditions for $U$ are equivalent:\n",
    "* $U^*$ is unitary.\n",
    "* $U^{-1} = U^*$\n",
    "* $U$ is normal and their eigenvalues are in the unit circle.\n",
    "* The columns of $U$ form an orthonormal basis of $\\mathbb{C}^n$.\n",
    "* The rows of $U$ form an orthonormal basis of $\\mathbb{C}^n$.\n",
    "\n",
    "Properties:\n",
    "* By definition, it is normal (i.e. $U^*U = UU^*$).\n",
    "  * $\\Rightarrow$ it is diagonalizable ($A = VDV^*$ with $V$ unitary and $D$ diagonal).\n",
    "  * Its eigenvectors for distinct eigenvalues are orthogonal (orthonormal in this case).\n",
    "* $|\\text{det}(U)| = 1$\n",
    "* Vector norms are preserved on multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Jacobian matrix\n",
    "\n",
    "A matrix $J$ that contains all the first-order partial derivates of a vector-valued function $\\mathbf{f}:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ :\n",
    "\n",
    "$$\n",
    "J(x_1,\\dots,x_n) = \\left[\n",
    "\\begin{matrix}\n",
    "\\frac{\\partial \\mathbf{f}}{\\partial x_1}\n",
    "& \\cdots\n",
    "& \\frac{\\partial \\mathbf{f}}{\\partial x_n}\n",
    "\\end{matrix} \\right]\n",
    "= \\left[\n",
    "\\begin{matrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n}\n",
    "\\\\ \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n",
    "\\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "* The best linear approximation of $\\mathbf{f}$ near a point $\\mathbf{p}$ is:\n",
    "$$\n",
    "\\mathbf{f}(\\mathbf{x})-\\mathbf{f}(\\mathbf{p}) = J(\\mathbf{p})(\\mathbf{x}-\\mathbf{p})\n",
    "$$\n",
    "* If $J(\\mathbf{x})$ is non-singular, $\\mathbf{f}$ is locally invertible near $\\mathbf{x}$.\n",
    "* The inverse of the Jacobian matrix $J$ of $\\mathbf{f}$ is the Jacobian matrix of $\\mathbf{f}^{-1}$.\n",
    "* It satiesfies the chain rule:\n",
    "$$\n",
    "J_{\\mathbf{g} \\circ \\mathbf{f}}(\\mathbf{x}) = J_{\\mathbf{g}}(\\mathbf{f}(\\mathbf{x})) J_{\\mathbf{f}}(\\mathbf{x}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) Projection matrix\n",
    "\n",
    "A matrix $P$ such that $P^2 = P$ (idempotent), that defines a transformation between the vector space $W$ to itself.\n",
    "\n",
    "* Its eigenvalues are $0$ or $1$.\n",
    "* Being $U = \\text{Rank}(P)$ and $V = \\text{Kern}(P)$:\n",
    "  * $\\forall x \\in U : Px = x$, i.e. $P$ is equivalent to the identity on the subspace $U$.\n",
    "  * Every vector $x \\in W$ may be decomposed uniquely as $x = u + v$, with $u = Px$ and $v = x - Px = (I-P) x$, where $u \\in U, v \\in V$.\n",
    "* If two projections commute, their product is a projection.\n",
    "* If $P$ projects onto a line with unit vector $u$, then $P=uu^T$.\n",
    "* If $P$ projects onto a subspace $U$ with $u_1,\\dots,u_k$ an arthonormal basis, then\n",
    "  $P = AA^T$, where $A$ is the $n \\times k$ matrix whose columns are $u_1,\\dots,u_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Companion matrix\n",
    "\n",
    "A square matrix defined for the polinomial:\n",
    "$$\n",
    "p(t) = c_0 + c_1 t + \\cdots + c_{n-1} t^{n-1} + t^n\n",
    "$$\n",
    "as\n",
    "$$\n",
    "C(p) = \\left[\n",
    "\\begin{matrix}\n",
    "0 & 0 & \\cdots & 0 & -c_0 \\\\\n",
    "1 & 0 & \\cdots & 0 & -c_1 \\\\\n",
    "0 & 1 & \\cdots & 0 & -c_2 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & 1 & -c_{n-1}\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "* A matrix $A$ is similar to the companion matrix $C$ of its characteristic polynomial (i.e. $\\exists P: C=P^{-1}AP$).\n",
    "  * Similar matrices share several properties, in that sense, analyzing $C$ could be more easy that analyzing $B$.\n",
    "  * Rank\n",
    "  * Characteristic polynomial\n",
    "    * Determinant\n",
    "    * Trace\n",
    "    * Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### j) Jacobi matrix\n",
    "\n",
    "A square tridiagonal matrix:\n",
    "$$\n",
    "A = \\left[\\begin{matrix}\n",
    "a_1 & b_1 & 0 & \\cdots & 0 & 0 \\\\\n",
    "c_1 & a_2 & b_2 & \\cdots & 0 & 0 \\\\\n",
    "0 & c_2 & a_3 & \\cdots & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\cdots & a_{n-1} & b_{n-1} \\\\\n",
    "0 & 0 & 0 & \\cdots & c_{n-1} & a_{n} \n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "so that $a_i \\neq 0 , \\forall i$.\n",
    "\n",
    "* The determinant can be computed from a three-term recurrence relation:\n",
    "  \\begin{align}\n",
    "  f_m &= a_m f_{m-1} - c_{m-1}b_{m-1}f_{m-2} \\\\\n",
    "  f_{-1} &= 0 \\\\\n",
    "  f_{0} &= 1\n",
    "  \\end{align}\n",
    "  where each $f_m$ is the determinant of the top-left $m\\times m$ submatrix and, thus, $\\text{det}(A) = f_n$.\n",
    "* The inverse can be obtained by a [known recurrence](https://en.wikipedia.org/w/index.php?title=Tridiagonal_matrix&oldid=905913546#Inversion).\n",
    "* If it is also Toeplitz (i.e. all values in the same diagonal are equal), which means $a_i =a \\, \\forall i$ ; $b_i =b \\, \\forall i$ ; $c_i =c \\, \\forall i$; the eigenvalues are:\n",
    "$$\n",
    "\\lambda_k = a+2\\sqrt{bc} \\cos\\left(\\frac{k\\pi}{n+1}\\right), \\quad k=1,\\dots,n\n",
    "$$\n",
    "* If $A$ is real and symmetric, then its eigenvalues are real. If all offdiagonal elements are nonzero, then they also are distinct.\n",
    "* [Numerous methods](https://www.sciencedirect.com/science/article/pii/S1063520312001042?via%3Dihub) exist for the numerical computation of the eigenvalues of a real symmetric tridiagonal matrix.\n",
    "* With [Lanczos algorithm](https://en.wikipedia.org/wiki/Lanczos_algorithm) it is possible to transform a Hermitian matrix to tridiagonal (and compute its eigenvalues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k) Defective matrix\n",
    "\n",
    "A $n \\times n$ matrix $A$ that doesn't have $n$ linearly independent eigenvectors.\n",
    "\n",
    "* $A$ has fewer than $n$ distinct eigenvalues. Repeated eigenvalues are called *defective*.\n",
    "* $A$ cannot be diagonalized.\n",
    "* Normal matrices are never defective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### l) Toeplitz matrix\n",
    "\n",
    "A matrix $A$ of size $n \\times n$ in which each descending diagonal from left to right is constant.\n",
    "$$\n",
    "A = \\left[ \\begin{matrix}\n",
    "a_0 & a_{-1} & a_{-2} & \\cdots & a_{-(n-1)} \\\\\n",
    "a_{1} & a_0 & a_{-1} & \\ddots & \\vdots \\\\\n",
    "a_{2} & a_{1} & a_0 & \\ddots & a_{-2} \\\\\n",
    "\\vdots & \\ddots & \\ddots & \\ddots & a_{-1} \\\\\n",
    "a_{n-1} & \\cdots & a_2 & a_1 & a_0\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "i.e. it is determined by the constants $c_{-(n{-}1)},\\dots,c_{n-1}$, so that\n",
    "$$\n",
    "a_{i,j} = c_{i-j}\n",
    "$$\n",
    "\n",
    "* The system $Ax = b$ (called Toeplitz system) can be solved using the [Levinson algorithm](https://en.wikipedia.org/wiki/Levinson_recursion) on $\\Theta(n^2)$ time.\n",
    "* $A$ can be decomposed ($LU$) in $O(n^2)$ time.\n",
    "* If $A$ is symmetric, it can be decomposed as:\n",
    "$$\n",
    "\\tfrac{1}{a_0} A = G G^T - (G-I) (G-I)^T\n",
    "$$\n",
    "where $G$ is the lower triangular part of $\\tfrac{1}{a_0}A$.\n",
    "* If $A$ is nonsingular and symmetric, we have that:\n",
    "$$\n",
    "A^{-1} = \\tfrac{1}{a_0}(B B^T - C C^T)\n",
    "$$\n",
    "where $B$ and $C$ are lower triangular Toeplitz matrices and $C$ is strictly lower.\n",
    "* It can be used to express a [discrete convolution](https://en.wikipedia.org/wiki/Toeplitz_matrix#Discrete_convolution) as matrix multiplication.\n",
    "\n",
    "Note: The definition sometimes is extended to include $n \\times m$ matrices but most properties don't apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m) Circulant matrix\n",
    "\n",
    "A Toeplitz matrix with the aditional condition that $a_i = a_{i+m}$.\n",
    "\n",
    "$$\n",
    "A = \\left[ \\begin{matrix}\n",
    "a_0 & a_{n-1} & a_{n-2} & \\cdots & a_{1} \\\\\n",
    "a_1 & a_0 & a_{n-1} & \\ddots & \\vdots \\\\\n",
    "a_2 & a_{1} & a_0 & \\ddots & a_{n-2} \\\\\n",
    "\\vdots & \\ddots & \\ddots & \\ddots & a_{n-1} \\\\\n",
    "a_{n-1} & \\cdots & a_2 & a_1 & a_0\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "The polynomial $f(x) = a_0 + a_1 x + a_2 x^2 + \\dots + a_{n-1}x^{n-1}$ is called the *asociated polynomial* of $A$.\n",
    "\n",
    "* It is fully specified by a vector $\\mathbf{a} = a_0,\\dots,a_{n-1}$.\n",
    "* They are diagonalized by a discrete Fourier transform.\n",
    "  * Equations that contain them may be quickly solved useing a FFT.\n",
    "  * The following matrix $U_n$ is composed of the eigenvectors of $A$:\n",
    "  $$\n",
    "  U_n^* = \\tfrac{1}{\\sqrt{n}}F_n \\quad \\text{and} \\quad U_n = \\sqrt{n}F_n^{-1} \\,,\n",
    "  $$\n",
    "  where $F_n = [f_{jk}]$ with $f_{jk} = e^{-2jk\\pi i/n},\\quad 0\\leq j,k < n$.\n",
    "  * $A = U_n \\text{diag}(F_n \\mathbf{a}) U_n^* = F_n^{-1} \\text{diag}(F_n \\mathbf{a})F_n.$\n",
    "  The eigenvalues of $A$ are given by $F_n \\mathbf{a}$ which can be calculated using a FFT.\n",
    "* The normalized eigenvectors are given by:\n",
    "$$\n",
    "v_j = \\tfrac{1}{\\sqrt{n}}(1,\\omega_j,\\omega_j^2,\\dots,\\omega_j^{n-1}), \\qquad \\forall j \\in [0,n{-}1] \\,,\n",
    "$$\n",
    "where $\\omega_j = \\text{exp}\\left( i \\tfrac{2 \\pi j}{n} \\right)$ (the $n$-th roots of unity).\n",
    "* The eigenvalues are given by:\n",
    "$$\n",
    "\\lambda_j = f(w_j), \\qquad \\forall j \\in [0,n{-}1] \\,.\n",
    "$$\n",
    "* $\\text{Rank}(A) = n-d$, where $d$ is the degree of the $\\text{gcd}(f(x),x^n-1)$.\n",
    "* If $A$ and $B$ are circulant, $A+B$ is circulant, $AB=BA$ is also circulant.\n",
    "* Given an equation $A\\mathbf{x} = \\mathbf{b}$, it can be written as a circular convolution:\n",
    "  $$\n",
    "  \\mathbf{a} \\star \\mathbf{x} = \\mathbf{b}\n",
    "  $$\n",
    "  Then $F_n(\\mathbf{a} \\star \\mathbf{x}) = F_n(\\mathbf{a})F_n(\\mathbf{x}) = F_n(\\mathbf{b})$ and then\n",
    "  $$\n",
    "  \\mathbf{x} = F_n^{-1}\\left[ \\left(\\frac{(F_n(\\mathbf{b}))_v}{(F_n(\\mathbf{a}))_v} \\right)_{v \\in Z} \\right]^T\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n) Hankel matrix\n",
    "\n",
    "A matrix $A$ of size $n \\times n$ in which each **ascending** diagonal from left to right is constant.\n",
    "$$\n",
    "A = \\left[ \\begin{matrix}\n",
    "a_0 & a_1 & a_2 & \\cdots & a_{n-1} \\\\\n",
    "a_1 & a_2 & a_3 & \\cdots & a_n  \\\\\n",
    "a_2 & a_3 & a_4 & \\cdots & a_{n+1} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{n-1} & a_{n} & a_{n+1} & \\cdots & a_{2n-2}\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "in other words\n",
    "$$\n",
    "A = [A_{ij} = a_{i+j-2}]\n",
    "$$\n",
    "\n",
    "* It is symmetric.\n",
    "* The determinant of the particular Hankel matrix:\n",
    "$$\n",
    "H_n = \\left[h_{ij} = \\begin{cases}\n",
    "0 & \\text{ if } i+j-1 > n \\\\\n",
    "i+j-1 & \\text{otherwise}\n",
    "\\end{cases}\\right] = \\left[\n",
    "\\begin{matrix}\n",
    "1 & 2 & 3 & \\cdots &  n{-}2 & n{-}1 & n \\\\\n",
    "2 & 3 & 4 & \\cdots &  n{-}1 & n & 0 \\\\\n",
    "3 & 4 & 5 & \\cdots &  n  & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots \\\\\n",
    "n{-}2 & n{-}1 & n & \\cdots & 0 & 0 & 0\\\\\n",
    "n{-}1 & n & 0  & \\cdots & 0 & 0 & 0 \\\\\n",
    "n  & 0 & 0  & \\cdots & 0 & 0 & 0 \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "is given by $\\text{det}(H_n) = (-1)^{\\lfloor n/2 \\rfloor} n^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### o) Hilbert matrix\n",
    "\n",
    "The Hilbert matrix is an specific $n \\times n$ matrix with the following form:\n",
    "$$\n",
    "H = \\left[h_{ij} = \\frac{1}{i+j-1}\\right] = \\left[\\begin{matrix}\n",
    "1 & \\tfrac{1}{2} & \\tfrac{1}{3} & \\cdots & \\tfrac{1}{n} \\\\\n",
    "\\tfrac{1}{2} & \\tfrac{1}{3} & \\tfrac{1}{4} & \\cdots & \\tfrac{1}{n{+}1} \\\\\n",
    "\\tfrac{1}{3} & \\tfrac{1}{4} & \\tfrac{1}{5} & \\cdots & \\tfrac{1}{n{+}2} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\tfrac{1}{n} & \\tfrac{1}{n{+}1} & \\tfrac{1}{n{+}2} & \\cdots & \\tfrac{1}{2n{-}1}\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "* They are canonical examples of ill-conditioned matrices.\n",
    "* It is a Hankel matrix.\n",
    "  * It is symmetric.\n",
    "* The determinant is:\n",
    "$$\n",
    "\\text{det}(H) = \\frac{c_n^4}{c_{2n}} \\,,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "c_n = \\prod_{i=1}^{n-1} i^{n-i} = \\prod_{i=1}^{n-1} i! \\, . \n",
    "$$\n",
    "* The inverse is given by:\n",
    "$$\n",
    "H^{-1} = \\left[h'_{ij} = (-1)^{i+j}(i+j-1)\\binom{n+i-1}{n-j} \\binom{n+j-1}{n-i} \\binom{i+j-2}{i-1}^2 \\right]\n",
    "$$\n",
    "  * All entries are integers.\n",
    "  * The signs form a checkerboard matrix, with the principal diagonal positive.\n",
    "* The condition number grows as $O\\left((1+\\sqrt{2})^{4n}\\middle/\\sqrt{n}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p) Markov matrix\n",
    "\n",
    "A matrix that describes the transitions of a Markov chain, where each entry represents a probability (non-negative), there are 3 kinds:\n",
    "* **right stochastic matrix**: each rows sums 1.\n",
    "* **left stochastic matrix**: each column sums 1.\n",
    "* **doubly stochastic matrix**: the whole matrix sums 1.\n",
    "\n",
    "For the first one we have that\n",
    "$$\n",
    "P = [p_{ij}] \\, ,\n",
    "$$\n",
    "with the condition that $\\sum_{j=1}^{n} p_{ij} = 1$, which is equivalent to:\n",
    "$$\n",
    "P \\mathbf{1} = \\mathbf{1}\n",
    "$$\n",
    "\n",
    "* The entry $p_{ij}$ represents the probability of transitioning from state $i$ to state $j$, where there are $n$ possible states. State probabilities should be multiplied by the left in order to advance the system.\n",
    "* The product of two right stochastic matrices is also stochastic: $P' P'' \\mathbf{1} = \\mathbf{1}$.\n",
    "* A probability vector $\\mathbf{\\pi}$  that's also a row eigenvector asociated to the eigenvalue $1$ represents a stationary distribution (that doesn't change under the application of the transition matrix):\n",
    "$$\n",
    "\\mathbf{\\pi} P = \\mathbf{\\pi} \\,.\n",
    "$$\n",
    "  * The system evolves over time to a static state:\n",
    "  $$\n",
    "  \\lim_{k \\rightarrow \\infty} P^k = \\Pi,\n",
    "  $$\n",
    "  where al $\\Pi$ rows are equal, and coincide with the vector $\\mathbf{\\pi}$. \n",
    "* The vector $\\mathbf{1}$ is a column eigenvector of $P$.\n",
    "* The spectral radius is at most $1$, moreover:\n",
    "$$\n",
    "|\\lambda - \\omega| \\leq 1-\\omega, \\quad \\text{where } \\omega = \\min_{1\\leq i \\leq n} p_{ii}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q) Differentiation matrices\n",
    "\n",
    "Its a matrix that when multiplied with a discrete approximation for a function $y(x)$, at some fixed points $x_j, j \\in 0,\\dots,n$ retrieves a numerical discrete approximation a derivate of $y$.\n",
    "\n",
    "These matrices are equivalent to fiting a function $p$ to the data, differentiating this approximation and evaluating this differentiation.\n",
    "\n",
    "For instance:\n",
    "$$\n",
    "D = \\frac{1}{h^2}\\left[\\begin{matrix}\n",
    "1 & -1 \\\\\n",
    "-1 & 2 & -1 \\\\\n",
    "& -1 & 2 & -1 \\\\\n",
    "& & \\ddots & \\ddots & \\ddots \\\\\n",
    "& & & -1 & 2 & -1 \\\\\n",
    "& & & & -1 & 2 & -1 \\\\\n",
    "& & & & & -1 & 1 \\\\\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "performs an approximation of $y''(x)$ using second-order central difference.\n",
    "\n",
    "The approximation is performed:\n",
    "$$\n",
    "D \\mathbf{y} = \\mathbf{y''}\n",
    "$$\n",
    "where $\\mathbf{y} = [y(x_j)]$ and $\\mathbf{y''}$ is the approximation of $[y''(x_j)]$.\n",
    "\n",
    "* Spectral methods use basis functions that are nonzero over the whole domain (they are **global**), for instance, $p(x)$ being a polynomial of degree $n$. Differentiation matrices are dense.\n",
    "* Finite element methods use basis functions that are nonzero only on small subdomains (they are **local**), for instance, using $p(x)$ as splines. Differentiation matrices are sparse.\n",
    "* The spectral element method chooses high degree piecewise polynomials as basis functions, also achieving a very high order of accuracy. Such polynomials are usually orthogonal Chebyshev polynomials or very high order Legendre polynomials over non-uniformly spaced nodes.\n",
    "\n",
    "These matrices are used to represent the differentiation operator in order to solve differential equations.\n",
    "\n",
    "Powers $D^n$ can be used to represent the $(n)$ derivate of a function discretization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r) Spectral differentiation matrices\n",
    "\n",
    "Differentiation matrices that get better global approximations for derivates. These approximations have \"*spectral accuracy*\", i.e. error diminises exponentially with $n$.\n",
    "\n",
    "On multiplication, retrieves a vector of points $p'(x_j)$ (or a higher order derivate) where $p$ is a single function so that $p(x_j)=y_j$ and this function $p$ is (generally) nonzero over the domain.\n",
    "\n",
    "* For periodic grids: Fourier methods can be used, $p$ is chosen to be a sum of trigonometric functions.\n",
    "* For non periodic grids: Chebyshev methods can be used, $p$ is chosen to be a polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s) Chebyshev differentiation matrices\n",
    "\n",
    "A $(n{+}1) \\times (n{+}1)$ spectral differentiation matrix that evaluates the function at the Chebyshev points:\n",
    "$$\n",
    "x_j = \\cos(j\\pi/N),\\quad j = 0,\\dots,N\n",
    "$$\n",
    "\n",
    "On multiplication, retrieves a vector of the points $p'(x_j)$ where $p(x)$ is the unique polynomial of degree $N$ that interpolates the input points.\n",
    "\n",
    "For instance, for $n=2$:\n",
    "$$\n",
    "D = \\left[\n",
    "\\begin{matrix}\n",
    "\\tfrac{3}{2} & -2 & \\tfrac{1}{2} \\\\\n",
    "\\tfrac{1}{2} & 0 & -\\tfrac{1}{2} \\\\\n",
    "-\\tfrac{1}{2} & 2 & -\\tfrac{3}{2}\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
