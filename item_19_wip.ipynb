{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item XIX\n",
    "\n",
    "Implement the Conjugate Gradient Method with symmetric preconditioner. Select a convenient problem of your choice, but not a trivial one and test it. Please describe the problem and implementation completely.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a regular version of the Conjugate Gradient, but generalized\n",
    "# so the way that the multiplications by the matrix A are done can be\n",
    "# be replaced\n",
    "def conjugate_gradient(A,b,pinv=lambda x:x,x0=None):\n",
    "    n = A.shape[0]\n",
    "    if x0 is None: x0 = np.zeros(n)\n",
    "    #\n",
    "    r0 = b - np.dot(A,x0)\n",
    "    z0 = pinv(r0)\n",
    "    p0 = z0\n",
    "    #\n",
    "    xk = x0\n",
    "    rk = r0\n",
    "    pk = p0\n",
    "    zk = z0\n",
    "    #\n",
    "    for k in range(n):\n",
    "        ak = np.dot(rk,zk)/np.dot(pk,np.dot(A,pk))\n",
    "        xk1 = xk + ak*pk\n",
    "        rk1 = rk - ak*np.dot(A,pk)\n",
    "        zk1 = pinv(rk1)\n",
    "        bk = np.dot(zk1,rk1)/np.dot(zk,rk)\n",
    "        pk1 = zk1 + bk*pk\n",
    "        # Move forward\n",
    "        xk = xk1\n",
    "        rk = rk1\n",
    "        pk = pk1\n",
    "        zk = zk1\n",
    "    return xk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.09190748 0.61823363 1.05819101 0.93441106 1.03996343]\n",
      " [0.61823363 6.14585374 0.98062608 0.85109716 1.07210015]\n",
      " [1.05819101 0.98062608 6.7145223  1.38233099 1.39712506]\n",
      " [0.93441106 0.85109716 1.38233099 6.69908011 1.75988505]\n",
      " [1.03996343 1.07210015 1.39712506 1.75988505 6.94552285]]\n",
      "[0.53405442 0.16455434 0.46100054 0.18008056 0.39653179]\n",
      "[ 0.0728593   0.00572985  0.04956425 -0.0037683   0.03628267]\n",
      "[ 0.0728593   0.00572985  0.04956425 -0.0037683   0.03628267]\n"
     ]
    }
   ],
   "source": [
    "def random_positive_definite_matrix(n):\n",
    "    a = np.random.random((n,n))\n",
    "    A = np.dot(a,a.T)\n",
    "    np.fill_diagonal(A,np.diag(A)+n)\n",
    "    return A\n",
    "N = 5\n",
    "A = random_positive_definite_matrix(N)\n",
    "b = np.random.random(N)\n",
    "print(A)\n",
    "print(b)\n",
    "x1 = np.linalg.solve(A,b)\n",
    "x2 = conjugate_gradient(A,b)\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the Jacobi preconditioner (the preconditioner is the diagonal of the matrix, so the inverse is simple):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_preconditioner_inv(A):\n",
    "    P = np.diag(A)**-1\n",
    "    return lambda x: P*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4988010832439613e-14\n",
      "3.164135620181696e-14\n",
      "6.661338147750939e-16\n",
      "7.771561172376096e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fcasas/Music/p36cpu/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "NS = (10,100,1000)\n",
    "\n",
    "for nn in NS:\n",
    "    AA = random_positive_definite_matrix(nn)\n",
    "    bb = np.random.random(nn)\n",
    "    xx = conjugate_gradient(AA,bb)\n",
    "    xx2 = conjugate_gradient(AA,bb,pinv=jacobi_preconditioner_inv(AA))\n",
    "    # Check maximum error:\n",
    "    max_err = np.max(np.abs(np.dot(AA,xx)-bb))\n",
    "    print(max_err)\n",
    "    max_err2 = np.max(np.abs(np.dot(AA,xx2)-bb))\n",
    "    print(max_err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
